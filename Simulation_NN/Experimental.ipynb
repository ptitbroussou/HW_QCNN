{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-18T09:36:46.160114Z",
     "start_time": "2024-04-18T09:36:44.060602Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F  # functions of the neural network library\n",
    "import load_dataset as load  # module with function to load data\n",
    "from Conv_Layer import *\n",
    "from torch.nn import AdaptiveAvgPool2d\n",
    "from Pooling import *\n",
    "import gc\n",
    "import time\n",
    "from Dense import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def float_to_int(x):\n",
    "    # Check if the decimal part is non-zero\n",
    "    if x - x.int() > 0.5:\n",
    "        return x.int() + 1\n",
    "    else:\n",
    "        return x.int()\n",
    "\n",
    "def batch_float_to_int(x):\n",
    "    return torch.tensor([float_to_int(xi) for xi in x])\n",
    "\n",
    "def copy_images(images, number_copies):\n",
    "    \"\"\" \n",
    "    Args:\n",
    "        images: tensor batch * I * I\n",
    "\n",
    "    Returns: tensor batch * number_copies * I * I\n",
    "    \"\"\"\n",
    "    images_unsqueezed = images.unsqueeze(1)\n",
    "    images_repeated = images_unsqueezed.repeat(1, number_copies, 1, 1)\n",
    "    return images_repeated\n",
    "\n",
    "\n",
    "def copy_images_bottom_channel(images, J):\n",
    "    images = images.unsqueeze(1)\n",
    "    upscaled_x = F.interpolate(images, size=(images.size()[-1]*J, images.size()[-1]*J), mode='nearest')\n",
    "    upscaled_x = upscaled_x.squeeze(1)\n",
    "    return upscaled_x\n",
    "\n",
    "# conv = Conv_RBS_density_I2_3D(I,K,J,device)\n",
    "# \n",
    "# for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#     new_size = I\n",
    "#     adaptive_avg_pool = AdaptiveAvgPool2d((new_size, new_size))\n",
    "#     data = adaptive_avg_pool(data).to(device)\n",
    "#     init_density_matrix = to_density_matrix(F.normalize(data.squeeze().resize(data.size()[0],I**2), p=2, dim=1).to(device), device)\n",
    "#     print(init_density_matrix.shape)\n",
    "#     copied_density_matrix = copy_images_bottom_channel(init_density_matrix, J)\n",
    "#     print(copied_density_matrix.shape)\n",
    "#     conv(copied_density_matrix)\n",
    "#     break\n",
    "\n",
    "\n",
    "\n",
    "def normalize_and_scale(tensor):\n",
    "    # Assuming the tensor is 10x1 and values roughly from -100 to 100\n",
    "    min_val = tensor.min()\n",
    "    max_val = tensor.max()\n",
    "    normalized_tensor = (tensor - min_val) / (max_val - min_val)\n",
    "    scaled_tensor = normalized_tensor * 9\n",
    "    return scaled_tensor\n",
    "\n",
    "\n",
    "class MeasureLayer(nn.Module):\n",
    "    def __init__(self, batch_size, I, J, device):\n",
    "        super().__init__()\n",
    "        # Initialize the tensor as a parameter, requiring gradients\n",
    "        self.observable = nn.Parameter(torch.randn(batch_size, I*I*J, I*I*J), requires_grad=True).to(device)\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def forward(self, rho):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            rho: tensor size batch * dimension * dimension\n",
    "        Returns: list of prediction, float\n",
    "        \"\"\"\n",
    "        rho = rho.to(self.device)\n",
    "        output = torch.stack([torch.trace(torch.matmul(rho[i], self.observable[i])).float().to(self.device) for i in range(self.batch_size)]).to(device)\n",
    "        return normalize_and_scale(output)\n",
    "\n",
    "\n",
    "class MeasureHWLayer(nn.Module):\n",
    "    def __init__(self, batch_size, I, J, device):\n",
    "        super().__init__()\n",
    "        # Initialize the tensor as a parameter, requiring gradients\n",
    "        self.observable = nn.Parameter(torch.randn(batch_size, int(binom(I+I+J, k)), int(binom(I+I+J, k))), requires_grad=True).to(device)\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def forward(self, rho):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            rho: tensor size batch * dimension * dimension\n",
    "        Returns: list of prediction, float\n",
    "        \"\"\"\n",
    "        rho = rho.to(self.device)\n",
    "        output = torch.stack([torch.trace(torch.matmul(rho[i], self.observable[i])).float().to(self.device) for i in range(self.batch_size)]).to(device)\n",
    "        return normalize_and_scale(output)\n",
    "\n",
    "\n",
    "\n",
    "class TrainedMeasureLayer(nn.Module):\n",
    "    def __init__(self, batch_size, observable, device):\n",
    "        super().__init__()\n",
    "        # Initialize the tensor as a parameter, requiring gradients\n",
    "        self.observable = observable.to(device)\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def forward(self, rho):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            rho: tensor size batch * dimension * dimension\n",
    "        Returns: list of prediction, float\n",
    "        \"\"\"\n",
    "        rho = rho.to(self.device)\n",
    "        output = torch.stack([torch.trace(torch.matmul(rho[i], self.observable[i])).float().to(self.device) for i in range(self.batch_size)]).to(device)\n",
    "        return normalize_and_scale(output)\n",
    "\n",
    "\n",
    "class MeasureLayerTrained(nn.Module):\n",
    "    def __init__(self, batch_size, trained_observable_diagonal, device):\n",
    "        super().__init__()\n",
    "        self.diagonal_element = trained_observable_diagonal\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def forward(self, rho):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            rho: tensor size batch * dimension * dimension\n",
    "        Returns: list of prediction, float\n",
    "        \"\"\"\n",
    "        rho = rho.to(self.device)\n",
    "        output = torch.stack([torch.trace(torch.matmul(rho[i], torch.diag(self.diagonal_element))).float().to(self.device) for i in range(self.batch_size)]).to(device)\n",
    "        return normalize_and_scale(output)\n",
    "\n",
    "\n",
    "class Tomograph_state(nn.Module):\n",
    "    def __init__(self, out, device):\n",
    "        super().__init__()\n",
    "        self.out = out\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, input):\n",
    "        data = F.relu(input[:,-self.out:,-self.out:])\n",
    "        return F.normalize(data, p=2, dim=1).to(self.device)\n",
    "\n",
    "\n",
    "def map_HW_to_distribution(batch_x, I, J, k, batch, device):\n",
    "    output = I + I + J\n",
    "    diagonal_x = torch.stack([torch.diag(x) for x in batch_x]).to(device)\n",
    "    y = torch.zeros(batch, output).to(device)\n",
    "    map = map_RBS(I + I + J, k)\n",
    "    for b in range(batch):\n",
    "        for key, value in map.items():\n",
    "            coef = diagonal_x[b][value]\n",
    "            y[b][key[0]] += coef\n",
    "            y[b][key[1]] += coef\n",
    "            y[b][key[2]] += coef\n",
    "    return y\n",
    "\n",
    "\n",
    "def map_HW_to_measure(batch_x, I, J, k, batch, device):\n",
    "    return torch.stack([torch.diag(x) for x in batch_x]).to(device)\n",
    "\n",
    "\n",
    "def get_reduced_layers_structure(n, out):\n",
    "    list_gates = []\n",
    "    PQNN_param_dictionary, PQNN_dictionary, PQNN_layer = PQNN_building_brick(0, 8, index_first_RBS=0, index_first_param=0)\n",
    "    for x, y in PQNN_dictionary.items():\n",
    "        list_gates.append((y,y+1))\n",
    "    list_gates.reverse()\n",
    "    # print(list_gates)\n",
    "\n",
    "    list_gates_delete = []\n",
    "    PQNN_param_dictionary, PQNN_dictionary, PQNN_layer = PQNN_building_brick(0, n-out, index_first_RBS=0, index_first_param=0)\n",
    "    for x, y in PQNN_dictionary.items():\n",
    "        list_gates_delete.append((y,y+1))\n",
    "    # print(list_gates_delete) \n",
    "\n",
    "    for e in list_gates_delete:\n",
    "        list_gates.remove(e)\n",
    "    list_gates.reverse()\n",
    "    return list_gates\n",
    "\n",
    "# # Example of using the class\n",
    "# I = 2\n",
    "# J = I# Dimension of the tensor\n",
    "# dimension = I*I*J\n",
    "# batch_size = 10\n",
    "# device = torch.device(\"mps\")\n",
    "\n",
    "# model = MeasureLayer(batch_size, I, J, device_cpu)\n",
    "# # x = torch.eye(dimension,dimension).to(device_cpu)\n",
    "# x = torch.randn(10, dimension,dimension).to(device)\n",
    "# y = torch.tensor((5,5,5,5,5,5,5,5,5,5), dtype=torch.float32).to(device_cpu)\n",
    "# print(model(x))\n",
    "# criterion = torch.nn.MSELoss(reduction='sum')\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "# for t in range(2000):\n",
    "#     model.train()\n",
    "#     # Forward pass: Compute predicted y by passing x to the model\n",
    "#     y_pred = model(x)\n",
    "#     # Compute and print loss\n",
    "#     loss = criterion(y_pred.to(device_cpu), y)\n",
    "#     # if t % 100 == 99:\n",
    "#     #     print(t, loss.item())\n",
    "# \n",
    "#     # Zero gradients, perform a backward pass, and update the weights.\n",
    "#     optimizer.zero_grad()\n",
    "#     # loss.requires_grad = True\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "# \n",
    "# print(model(x))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T09:36:47.169388Z",
     "start_time": "2024-04-18T09:36:47.145672Z"
    }
   },
   "id": "60e6ba154a15c868"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# import torch\n",
    "# \n",
    "# def transform_input(input_tensor, output_size):\n",
    "#     batch, input_size = input_tensor.shape\n",
    "# \n",
    "#     step = input_size // output_size\n",
    "#     # Initialize an output tensor\n",
    "#     output_tensor = torch.zeros((batch, output_size), dtype=input_tensor.dtype)\n",
    "#     for i in range(output_size):\n",
    "#         # Sum up 'step' number of elements for each segment of the input\n",
    "#         output_tensor[:, i] = input_tensor[:, i*step:(i+1)*step].sum(dim=1)\n",
    "#     return output_tensor\n",
    "# \n",
    "# # Example usage\n",
    "# batch = 2\n",
    "# input_size = 22\n",
    "# output_size = 10\n",
    "# input_tensor = torch.randn(batch, input_size)\n",
    "# output_tensor = transform_input(input_tensor, output_size)\n",
    "# print(input_tensor)\n",
    "# print(output_tensor)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T09:58:52.692994Z",
     "start_time": "2024-04-12T09:58:52.686794Z"
    }
   },
   "id": "46d69e861aff3d2"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 56, 56])\n"
     ]
    },
    {
     "data": {
      "text/plain": "torch.Size([1, 8])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def map_HW_to_distribution(batch_x, I, J, k, batch, device):\n",
    "#     output = I+I+J\n",
    "#     diagonal_x = torch.stack([torch.diag(x) for x in batch_x]).to(device)\n",
    "#     y = torch.zeros(batch,output).to(device)\n",
    "#     map = map_RBS(I+I+J,k)\n",
    "#     for b in range(batch):\n",
    "#         for key, value in map.items():\n",
    "#             coef = diagonal_x[b][value]\n",
    "#             y[b][key[0]] += coef\n",
    "#             y[b][key[1]] += coef\n",
    "#             y[b][key[2]] += coef\n",
    "#     return y\n",
    "# \n",
    "# def map_HW_to_measure(batch_x, I, J, k, batch, device):\n",
    "#     return torch.stack([torch.diag(x)[-10:] for x in batch_x]).to(device)\n",
    "# I = 3\n",
    "# J = 2\n",
    "# k = 3\n",
    "# batch = 1\n",
    "# device = torch.device(\"mps\")\n",
    "# size = int(binom(I+I+J,k))\n",
    "# batch_x = torch.randn(batch,size,size).to(device)\n",
    "# print(batch_x.shape)\n",
    "# map_HW_to_distribution(batch_x, I, J, k, batch, device).shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T17:22:12.050477Z",
     "start_time": "2024-04-10T17:22:11.820511Z"
    }
   },
   "id": "a549932095aa1508"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 84, 84])\n"
     ]
    },
    {
     "data": {
      "text/plain": "torch.Size([2, 10])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I = 3\n",
    "# J = 3\n",
    "# k = 3\n",
    "# batch = 2\n",
    "# device = torch.device(\"mps\")\n",
    "# size = int(binom(I+I+J,k))\n",
    "# batch_x = torch.randn(batch,size,size).to(device)\n",
    "# print(batch_x.shape)\n",
    "# map_HW_to_measure(batch_x, I, J, k, batch, device).shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T17:28:45.168078Z",
     "start_time": "2024-04-10T17:28:45.033544Z"
    }
   },
   "id": "48086424231dfcc2"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# import torch\n",
    "# \n",
    "# \n",
    "# \n",
    "# # Example\n",
    "# input_tensor = torch.randn(10, 1) * 100  # Generating a tensor with values roughly from -100 to 100\n",
    "# output_tensor = normalize_and_scale(input_tensor)\n",
    "# \n",
    "# print(output_tensor)\n",
    "def Passage_matrix_I_to_HW_3D(I, J, k, device):\n",
    "    \"\"\" This function outputs a tensor matrix that allows to pass from the\n",
    "    Image basis to the HW basis. We assume to consider square images with no\n",
    "    channels.\n",
    "    Args:\n",
    "        - I: size of the input image\n",
    "        - device: torch device (cpu, cuda, etc...)\n",
    "    Output:\n",
    "        - Passage_matrix: tensor matrix of size (int(binom(2*I,2)), I**2) that allows\n",
    "        to pass from the Image basis to the HW basis.\n",
    "    \"\"\"\n",
    "    Passage_matrix = torch.zeros((int(binom(I+I+J,k)), I*I*J), dtype=torch.uint8, device=device)\n",
    "    mapping_input = map_RBS_I2_3D_bottom(I,J)\n",
    "    mapping_output = map_RBS(I+I+J,k)\n",
    "    for line in range(I):\n",
    "        for column in range(I):\n",
    "            for channel in range(J):\n",
    "                # print(\"line: \" + str(line) + \", \" + str(I+column) + \", \" + str(2*I+channel) )\n",
    "                output_index = mapping_output[(line, I+column, 2*I+channel)]\n",
    "                intput_index = mapping_input[(line, I+column, 2*I+channel)]\n",
    "                Passage_matrix[output_index, intput_index] = 1\n",
    "    return(Passage_matrix)\n",
    "\n",
    "\n",
    "class Basis_Change_I_to_HW_density_3D(nn.Module):\n",
    "    \"\"\" This module allows to change the basis from the Image basis to the HW basis.\"\"\"\n",
    "\n",
    "    def __init__(self, I, J, k, device):\n",
    "        \"\"\" We suppose that the input image is square and we consider no channels. \"\"\"\n",
    "        super().__init__()\n",
    "        self.Passage_matrix = Passage_matrix_I_to_HW_3D(I, J, k, device).to(torch.float)\n",
    "\n",
    "    def forward(self, input_state):\n",
    "        \"\"\" This module forward a tensor made of each pure sate weighted by their\n",
    "        probabilities that describe the output mixted state form the pooling layer. \n",
    "        Arg:\n",
    "            - input: a torch vector representing the initial input state. Its\n",
    "            dimension is (nbr_batch, I**2, I**2).\n",
    "        Output:\n",
    "            - a torch density operator that represents the output mixted state in\n",
    "            the basis of HW 2. Its dimension is (nbr_batch, binom(2*I,2), binom(2*I,2)).\n",
    "        \"\"\"\n",
    "        # input_state = torch.einsum('bii, oi->boi', input_state, self.Passage_matrix.to(torch.float32))\n",
    "        # input_state = torch.einsum('boi, ai->boa', input_state, self.Passage_matrix.to(torch.float32))\n",
    "        # return (input_state)\n",
    "        return self.Passage_matrix @ input_state @ self.Passage_matrix.T\n",
    "\n",
    "class Dense_RBS_density_3D(nn.Module):\n",
    "    \"\"\" This module describes the action of one RBS based VQC. \"\"\"\n",
    "\n",
    "    def __init__(self, I, J, k, list_gates, device):\n",
    "        \"\"\" Args:\n",
    "            - I: size of the square input image\n",
    "            - list_gates: list of tuples representing the qubits affected by each RBS\n",
    "            - device: torch device (cpu, cuda, etc...) \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # We only store the RBS unitary corresponding to an edge in the qubit connectivity: \n",
    "        self.RBS_Unitaries_dict = RBS_Unitaries(I+I+J, k, list_gates, device)\n",
    "        self.RBS_gates = nn.ModuleList([RBS_Dense_density(list_gates[i], device) for i in range(len(list_gates))])\n",
    "\n",
    "    def forward(self, input_state):\n",
    "        \"\"\" Feedforward of the RBS based VQC.\n",
    "        Arg:\n",
    "            - input_state = a density operator on which is applied the RBS from the \n",
    "            VQC. Its dimension is (nbr_batch, binom(2*I,2), binom(2*I,2))\n",
    "        Output:\n",
    "            - final density operator from the application of the RBS from the VQC on\n",
    "            the input density operator. Its dimension is (nbr_batch, binom(2*I,2), binom(2*I,2)).\n",
    "        \"\"\"\n",
    "        input_state = input_state.float()\n",
    "        for RBS in self.RBS_gates:\n",
    "            input_state = RBS(input_state, self.RBS_Unitaries_dict)\n",
    "        return (input_state)\n",
    "\n",
    "\n",
    "class Dense_RBS_density_3D_para(nn.Module):\n",
    "    \"\"\" This module describes the action of one RBS based VQC. \"\"\"\n",
    "\n",
    "    def __init__(self, I, J, k, list_gates, angles, device):\n",
    "        \"\"\" Args:\n",
    "            - I: size of the square input image\n",
    "            - list_gates: list of tuples representing the qubits affected by each RBS\n",
    "            - angles: with length list_gates\n",
    "            - device: torch device (cpu, cuda, etc...) \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # We only store the RBS unitary corresponding to an edge in the qubit connectivity: \n",
    "        self.RBS_Unitaries_dict = RBS_Unitaries(I+I+J, k, list_gates, device)\n",
    "        self.RBS_gates = nn.ModuleList([RBS_Dense_density_para(list_gates[i], angles[i], device) for i in range(len(list_gates))])\n",
    "\n",
    "    def forward(self, input_state):\n",
    "        \"\"\" Feedforward of the RBS based VQC.\n",
    "        Arg:\n",
    "            - input_state = a density operator on which is applied the RBS from the \n",
    "            VQC. Its dimension is (nbr_batch, binom(2*I,2), binom(2*I,2))\n",
    "        Output:\n",
    "            - final density operator from the application of the RBS from the VQC on\n",
    "            the input density operator. Its dimension is (nbr_batch, binom(2*I,2), binom(2*I,2)).\n",
    "        \"\"\"\n",
    "        input_state = input_state.float()\n",
    "        for RBS in self.RBS_gates:\n",
    "            input_state = RBS(input_state, self.RBS_Unitaries_dict)\n",
    "        return (input_state)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T09:36:50.659896Z",
     "start_time": "2024-04-18T09:36:50.657935Z"
    }
   },
   "id": "e239e170e8755c20"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1466, device='mps:0', grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "I = 3\n",
    "O = I//2\n",
    "n = 2*I\n",
    "k = 3\n",
    "K = I\n",
    "J = 2\n",
    "device = torch.device(\"mps\")\n",
    "device_cpu = torch.device(\"mps\")\n",
    "batch_size = 1\n",
    "\n",
    "list_gates_pyramid = []\n",
    "angles = []\n",
    "PQNN_param_dictionary, PQNN_dictionary, PQNN_layer = PQNN_building_brick(0, I+I+J, index_first_RBS=0, index_first_param=0)\n",
    "for x, y in PQNN_dictionary.items():\n",
    "    list_gates_pyramid.append((y,y+1))\n",
    "    angles.append(0.31)\n",
    "\n",
    "list_gates_pyramid_reduced = get_reduced_layers_structure(I+I+J, 5)\n",
    "angles_reduced = [0.31 for i in range(len(list_gates_pyramid_reduced))]\n",
    "\n",
    "# list_gates_pyramid2 = []\n",
    "# PQNN_param_dictionary, PQNN_dictionary, PQNN_layer = PQNN_building_brick(0, 5, index_first_RBS=0, index_first_param=0)\n",
    "# for x, y in PQNN_dictionary.items():\n",
    "#     list_gates_pyramid2.append((y,y+1))\n",
    "\n",
    "list_gates_naive = [(6,7)]\n",
    "angles_naive = [0.31]\n",
    "dense_naive = Dense_RBS_density_3D_para(I, J, k, list_gates_naive, angles_naive, device)\n",
    "\n",
    "\n",
    "dimension = int(binom(I+I+J, k))\n",
    "dense1 = Dense_RBS_density_3D_para(I, J, k, list_gates_pyramid, angles, device)\n",
    "dense1_reduced = Dense_RBS_density_3D_para(I, J, k, list_gates_pyramid_reduced, angles_reduced, device)\n",
    "tomo = Tomograph_state(10, device)\n",
    "tomop = Tomograph_state(10, device)\n",
    "# dense2 = Dense_RBS_density_3D(0, 5, k, list_gates_pyramid2, device)\n",
    "\n",
    "x = torch.randn(batch_size, dimension, dimension).to(device)\n",
    "d1 = dense1(x)\n",
    "d2 = dense1(x)\n",
    "d1p = dense_naive(d2)\n",
    "# print(torch.sum(d1[0][-10:,-10:]-d1p[0][-10:,-10:]))\n",
    "# print(d1.shape)\n",
    "# print(d1p.shape)\n",
    "tomo = tomo(d1)\n",
    "tomop = tomop(d1p)\n",
    "print(torch.sum(tomop-tomo))\n",
    "# d2 = dense2(tomo)\n",
    "# d2.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T17:01:35.897325Z",
     "start_time": "2024-04-15T17:01:35.779853Z"
    }
   },
   "id": "39e662fde7a8e60d"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 176.554815, accuracy = 10.0000 %\n",
      "Epoch 1: Loss = 135.451085, accuracy = 16.6667 %\n",
      "Epoch 2: Loss = 132.114540, accuracy = 13.3333 %\n",
      "Epoch 3: Loss = 130.146144, accuracy = 16.6667 %\n",
      "Epoch 4: Loss = 128.482192, accuracy = 20.0000 %\n",
      "Epoch 5: Loss = 126.988327, accuracy = 20.0000 %\n",
      "Epoch 6: Loss = 125.584359, accuracy = 21.6667 %\n",
      "Epoch 7: Loss = 124.202453, accuracy = 21.6667 %\n",
      "Epoch 8: Loss = 122.785531, accuracy = 23.3333 %\n",
      "Epoch 9: Loss = 121.297185, accuracy = 25.0000 %\n",
      "Epoch 10: Loss = 119.756743, accuracy = 25.0000 %\n",
      "Epoch 11: Loss = 118.279426, accuracy = 21.6667 %\n",
      "Epoch 12: Loss = 116.766685, accuracy = 21.6667 %\n",
      "Epoch 13: Loss = 118.514075, accuracy = 21.6667 %\n",
      "Epoch 14: Loss = 112.010890, accuracy = 18.3333 %\n",
      "Epoch 15: Loss = 110.431975, accuracy = 20.0000 %\n",
      "Epoch 16: Loss = 108.331834, accuracy = 21.6667 %\n",
      "Epoch 17: Loss = 106.515694, accuracy = 16.6667 %\n",
      "Epoch 18: Loss = 105.260644, accuracy = 18.3333 %\n",
      "Epoch 19: Loss = 103.880637, accuracy = 20.0000 %\n",
      "Epoch 20: Loss = 98.130507, accuracy = 25.0000 %\n",
      "Epoch 21: Loss = 92.713819, accuracy = 18.3333 %\n",
      "Epoch 22: Loss = 77.840838, accuracy = 16.6667 %\n",
      "Epoch 23: Loss = 78.248471, accuracy = 16.6667 %\n",
      "Epoch 24: Loss = 67.890583, accuracy = 16.6667 %\n",
      "Epoch 25: Loss = 56.713879, accuracy = 15.0000 %\n",
      "Epoch 26: Loss = 70.790576, accuracy = 15.0000 %\n",
      "Epoch 27: Loss = 65.219866, accuracy = 21.6667 %\n",
      "Epoch 28: Loss = 71.491587, accuracy = 8.3333 %\n",
      "Epoch 29: Loss = 53.100214, accuracy = 21.6667 %\n",
      "Epoch 30: Loss = 49.489872, accuracy = 21.6667 %\n",
      "Epoch 31: Loss = 43.490746, accuracy = 21.6667 %\n",
      "Epoch 32: Loss = 42.391622, accuracy = 16.6667 %\n",
      "Epoch 33: Loss = 41.775366, accuracy = 23.3333 %\n",
      "Epoch 34: Loss = 41.044154, accuracy = 25.0000 %\n",
      "Epoch 35: Loss = 40.125891, accuracy = 26.6667 %\n",
      "Epoch 36: Loss = 38.992860, accuracy = 28.3333 %\n",
      "Epoch 37: Loss = 38.020895, accuracy = 30.0000 %\n",
      "Epoch 38: Loss = 37.099970, accuracy = 31.6667 %\n",
      "Epoch 39: Loss = 36.253485, accuracy = 31.6667 %\n",
      "Epoch 40: Loss = 35.489203, accuracy = 31.6667 %\n",
      "Epoch 41: Loss = 34.818607, accuracy = 30.0000 %\n",
      "Epoch 42: Loss = 33.955096, accuracy = 28.3333 %\n",
      "Epoch 43: Loss = 33.760525, accuracy = 31.6667 %\n",
      "Epoch 44: Loss = 31.908090, accuracy = 30.0000 %\n",
      "Epoch 45: Loss = 39.531053, accuracy = 26.6667 %\n",
      "Epoch 46: Loss = 29.419473, accuracy = 25.0000 %\n",
      "Epoch 47: Loss = 28.675996, accuracy = 26.6667 %\n",
      "Epoch 48: Loss = 28.346938, accuracy = 30.0000 %\n",
      "Epoch 49: Loss = 25.890007, accuracy = 26.6667 %\n",
      "Epoch 50: Loss = 24.953873, accuracy = 30.0000 %\n",
      "Epoch 51: Loss = 23.614673, accuracy = 33.3333 %\n",
      "Epoch 52: Loss = 22.996306, accuracy = 31.6667 %\n",
      "Epoch 53: Loss = 22.498675, accuracy = 31.6667 %\n",
      "Epoch 54: Loss = 21.825162, accuracy = 33.3333 %\n",
      "Epoch 55: Loss = 21.204345, accuracy = 33.3333 %\n",
      "Epoch 56: Loss = 20.716438, accuracy = 33.3333 %\n",
      "Epoch 57: Loss = 20.329813, accuracy = 31.6667 %\n",
      "Epoch 58: Loss = 19.845414, accuracy = 31.6667 %\n",
      "Epoch 59: Loss = 19.424109, accuracy = 31.6667 %\n",
      "Epoch 60: Loss = 19.003467, accuracy = 31.6667 %\n",
      "Epoch 61: Loss = 18.626332, accuracy = 31.6667 %\n",
      "Epoch 62: Loss = 18.269529, accuracy = 31.6667 %\n",
      "Epoch 63: Loss = 17.935913, accuracy = 31.6667 %\n",
      "Epoch 64: Loss = 17.619027, accuracy = 31.6667 %\n",
      "Epoch 65: Loss = 17.318827, accuracy = 31.6667 %\n",
      "Epoch 66: Loss = 17.033655, accuracy = 31.6667 %\n",
      "Epoch 67: Loss = 16.762647, accuracy = 35.0000 %\n",
      "Epoch 68: Loss = 16.504656, accuracy = 36.6667 %\n",
      "Epoch 69: Loss = 16.258702, accuracy = 38.3333 %\n",
      "Epoch 70: Loss = 16.024003, accuracy = 38.3333 %\n",
      "Epoch 71: Loss = 15.799740, accuracy = 40.0000 %\n",
      "Epoch 72: Loss = 15.585272, accuracy = 40.0000 %\n",
      "Epoch 73: Loss = 15.525143, accuracy = 43.3333 %\n",
      "Epoch 74: Loss = 15.445265, accuracy = 40.0000 %\n",
      "Epoch 75: Loss = 15.127982, accuracy = 43.3333 %\n",
      "Epoch 76: Loss = 14.954429, accuracy = 41.6667 %\n",
      "Epoch 77: Loss = 14.714311, accuracy = 40.0000 %\n",
      "Epoch 78: Loss = 14.561349, accuracy = 40.0000 %\n",
      "Epoch 79: Loss = 14.345089, accuracy = 40.0000 %\n",
      "Epoch 80: Loss = 14.190243, accuracy = 40.0000 %\n",
      "Epoch 81: Loss = 14.000427, accuracy = 40.0000 %\n",
      "Epoch 82: Loss = 13.893545, accuracy = 40.0000 %\n",
      "Epoch 83: Loss = 13.675966, accuracy = 40.0000 %\n",
      "Epoch 84: Loss = 13.551685, accuracy = 41.6667 %\n",
      "Epoch 85: Loss = 13.415846, accuracy = 40.0000 %\n",
      "Epoch 86: Loss = 13.227783, accuracy = 41.6667 %\n",
      "Epoch 87: Loss = 13.231383, accuracy = 40.0000 %\n",
      "Epoch 88: Loss = 12.941328, accuracy = 40.0000 %\n",
      "Epoch 89: Loss = 13.242552, accuracy = 38.3333 %\n",
      "Epoch 90: Loss = 12.771618, accuracy = 43.3333 %\n",
      "Epoch 91: Loss = 12.720249, accuracy = 43.3333 %\n",
      "Epoch 92: Loss = 12.395124, accuracy = 43.3333 %\n",
      "Epoch 93: Loss = 12.527313, accuracy = 43.3333 %\n",
      "Epoch 94: Loss = 12.207992, accuracy = 45.0000 %\n",
      "Epoch 95: Loss = 11.942444, accuracy = 46.6667 %\n",
      "Epoch 96: Loss = 12.439363, accuracy = 43.3333 %\n",
      "Epoch 97: Loss = 12.233808, accuracy = 46.6667 %\n",
      "Epoch 98: Loss = 11.581680, accuracy = 46.6667 %\n",
      "Epoch 99: Loss = 11.829276, accuracy = 45.0000 %\n"
     ]
    }
   ],
   "source": [
    "I = 12\n",
    "O = I//2\n",
    "n = 2*I\n",
    "k = 3\n",
    "K = 2\n",
    "J = 2\n",
    "\n",
    "dimension = int(binom(I+I+J, k))\n",
    "final_dimension = int(binom(O+J, k))\n",
    "device = torch.device(\"mps\")\n",
    "device_cpu = torch.device(\"mps\")\n",
    "# trained_observable_diagonal = torch.linspace(-1, 1, steps=int(binom(O+J, k)))\n",
    "batch_size = 10  # the number of examples per batch\n",
    "observable = torch.randn(batch_size, final_dimension, final_dimension)\n",
    "class_number = 10\n",
    "train_loader, test_loader, dim_in, dim_out = load.load_MNIST(batch_size=batch_size)\n",
    "scala = 1000\n",
    "reduced_loader = reduce_MNIST_dataset(train_loader, scala)\n",
    "# list_gates_pyramid = []\n",
    "# PQNN_param_dictionary, PQNN_dictionary, PQNN_layer = PQNN_building_brick(0, I+I+J, index_first_RBS=0, index_first_param=0)\n",
    "# for x, y in PQNN_dictionary.items():\n",
    "#     list_gates_pyramid.append((y,y+1))\n",
    "#     \n",
    "# list_gates_pyramid2 = []\n",
    "# PQNN_param_dictionary, PQNN_dictionary, PQNN_layer = PQNN_building_brick(0, 5, index_first_RBS=0, index_first_param=0)\n",
    "# for x, y in PQNN_dictionary.items():\n",
    "#     list_gates_pyramid2.append((y,y+1))\n",
    "    \n",
    "list_gates = [(i, j) for i in range(O+J) for j in range(O+J) if i != j]\n",
    "\n",
    "# full_model = nn.Sequential(Conv_RBS_density_I2_3D(I,2,J,device),\n",
    "#                            Basis_Change_I_to_HW_density_3D(I, J, k, device),\n",
    "#                            Dense_RBS_density_3D(I, J, k, list_gates_pyramid, device),\n",
    "#                            Tomograph_state(class_number, device),\n",
    "#                            Dense_RBS_density_3D(0, 5, k, list_gates_pyramid2, device))\n",
    "# full_model = nn.Sequential(Conv_RBS_density_I2_3D(I,2,J,device),\n",
    "#                            Conv_RBS_density_I2_3D(I,3,J,device),\n",
    "#                            Basis_Change_I_to_HW_density_3D(I, J, k, device),\n",
    "#                            Dense_RBS_density_3D(I, J, k, list_gates_pyramid, device),\n",
    "#                            Tomograph_state(class_number, device),\n",
    "#                            Dense_RBS_density_3D(0, 5, k, list_gates_pyramid2, device))\n",
    "\n",
    "full_model = nn.Sequential(Conv_RBS_density_I2_3D(I,2,J,device),\n",
    "                           Pooling_2D_density_3D(I, O, J, device),\n",
    "                           Conv_RBS_density_I2_3D(O,2,J,device),\n",
    "                           Pooling_2D_density_3D(O, O//2, J, device),\n",
    "                           Basis_Change_I_to_HW_density_3D(O//2, J, k, device),\n",
    "                           Dense_RBS_density_3D(O//2, J, k, list_gates, device),\n",
    "                           TrainedMeasureLayer(batch_size, observable, device_cpu))\n",
    "\n",
    "loss_function = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.Adagrad(full_model.parameters(), lr=1e-1, lr_decay=1e-6, weight_decay=0, initial_accumulator_value=1e-6, eps=1e-10)\n",
    "\n",
    "# optimizer = torch.optim.Adam(full_model.parameters(), lr=1e-2)\n",
    "# loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train_net(network, train_loader, loss_function, optimizer, device):\n",
    "    network.train()\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        new_size = I\n",
    "        adaptive_avg_pool = AdaptiveAvgPool2d((new_size, new_size))\n",
    "        data = adaptive_avg_pool(data).to(device)\n",
    "        init_density_matrix = to_density_matrix(F.normalize(data.squeeze().resize(data.size()[0],I**2), p=2, dim=1).to(device), device)\n",
    "        copied_density_matrix = copy_images_bottom_channel(init_density_matrix, J).to(device)\n",
    "        out_network = network(copied_density_matrix)\n",
    "        # print(out_network.shape)\n",
    "        # out_network = map_HW_to_measure(out_network, I, J, k, batch_size, device)\n",
    "        # print(out_network.shape)\n",
    "        # print(target.shape)\n",
    "        # training\n",
    "        # targets = get_batch_projectors(target, batch_size, int(I*I*J), device)\n",
    "        loss = loss_function(out_network.to(device_cpu),target.float().to(device))\n",
    "        train_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # predict digital number\n",
    "        predict_number = batch_float_to_int(out_network.to(device_cpu))\n",
    "        acc = predict_number.eq(target.view_as(predict_number)).sum().item()\n",
    "        train_accuracy += acc\n",
    "        \n",
    "        # pred = out_network.argmax(dim=1, keepdim=True).to(device)  # the class chosen by the network is the highest output\n",
    "        # acc = pred.eq(target.to(device).view_as(pred)).sum().item()  # the accuracy is the proportion of correct classes\n",
    "        # train_accuracy += acc  # increment accuracy of whole test set\n",
    "\n",
    "        # delete variable to free memory\n",
    "        del out_network\n",
    "        gc.collect()\n",
    "\n",
    "    train_accuracy /= len(train_loader.dataset)\n",
    "    train_loss /= (batch_idx + 1)\n",
    "    return train_accuracy, train_loss\n",
    "\n",
    "\n",
    "for epoch in range(100):\n",
    "    # start = time.time()\n",
    "    train_accuracy, train_loss = train_net(full_model, reduced_loader, loss_function, optimizer, device)\n",
    "    print(f'Epoch {epoch}: Loss = {train_loss:.6f}, accuracy = {train_accuracy*100:.4f} %')\n",
    "    # end = time.time()\n",
    "    # print(\"The time of execution of above program is :\",(end-start), \"s\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T10:24:39.658787Z",
     "start_time": "2024-04-18T10:18:10.846447Z"
    }
   },
   "id": "8e5c69269b334590"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "env3.10",
   "language": "python",
   "display_name": "env3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
