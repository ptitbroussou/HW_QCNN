{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-27T09:42:48.312525Z",
     "start_time": "2024-05-27T09:42:46.067035Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from src import load_dataset as load\n",
    "from src.QCNN_layers.Conv_layer import Conv_RBS_density_I2_3D\n",
    "from src.QCNN_layers.Measurement_layer import measurement\n",
    "from src.QCNN_layers.Pooling_layer import Pooling_3D_density\n",
    "from src.training import train_globally\n",
    "from src.QCNN_layers.Dense_layer import Dense_RBS_density_3D, Basis_Change_I_to_HW_density_3D, Trace_out_dimension\n",
    "from src.list_gates import drip_circuit, full_pyramid_circuit\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "##################### Hyperparameters begin #######################\n",
    "# Below are the hyperparameters of this network, you can change them to test\n",
    "I = 8  # dimension of image we use. If you use 2 times conv and pool layers, please make it a multiple of 4\n",
    "O = I // 2  # dimension after pooling, usually you don't need to change this\n",
    "J = 4  # number of channel\n",
    "k = 3  # preserving subspace parameter, usually you don't need to change this\n",
    "K = 4  # size of kernel in the convolution layer, please make it divisible by O=I/2\n",
    "stride = 1 # the difference in step sizes for different channels\n",
    "batch_size = 10  # batch number\n",
    "training_dataset = 10  # training dataset sample number\n",
    "testing_dataset = 10  # testing dataset sample number\n",
    "is_shuffle = False # shuffle for this dataset\n",
    "learning_rate = 1e-1 # step size for each learning steps\n",
    "train_epochs = 10  # number of epoch we train\n",
    "test_interval = 10  # when the training epoch reaches an integer multiple of the test_interval, print the testing result\n",
    "criterion = torch.nn.CrossEntropyLoss() # loss function\n",
    "device = torch.device(\"cpu\")  # also torch.device(\"cpu\"), or torch.device(\"mps\") for macbook\n",
    "\n",
    "# Here you can modify the RBS gate list that you want for the dense layer:\n",
    "# dense_full_gates is for the case qubit=O+J, dense_reduce_gates is for the case qubit=5.\n",
    "# Why we need two dense gate lists? Because for the 10 labels classification we only need 10 dimension in the end,\n",
    "# so after the full dense we reduce the dimension from binom(O+J,3) to binom(5,3)=10, i.e., only keep the last 5 qubits.\n",
    "# Finally, we do the reduce dense for 5 qubits and measurement.\n",
    "# Also, you can check visualization of different gate lists in the file \"src/list_gates.py\"\n",
    "dense_full_gates = drip_circuit(O + J)\n",
    "dense_reduce_gates = full_pyramid_circuit(5)\n",
    "##################### Hyperparameters end #######################"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T09:42:49.577083Z",
     "start_time": "2024-05-27T09:42:49.565779Z"
    }
   },
   "id": "bff1aa30fc2b9be1"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training! Number of network total parameters: 68\n",
      "Evaluation on test set: Loss = 2.163734, accuracy = 20.0000 %\n",
      "Epoch 0: Loss = 2.141234, accuracy = 20.0000 %, time=1.7634s\n",
      "Epoch 1: Loss = 2.186247, accuracy = 10.0000 %, time=1.6703s\n",
      "Epoch 2: Loss = 2.113597, accuracy = 30.0000 %, time=1.6252s\n",
      "Epoch 3: Loss = 2.066203, accuracy = 30.0000 %, time=1.6317s\n",
      "Epoch 4: Loss = 2.099340, accuracy = 20.0000 %, time=1.6318s\n",
      "Epoch 5: Loss = 2.089441, accuracy = 20.0000 %, time=1.6511s\n",
      "Epoch 6: Loss = 2.060739, accuracy = 20.0000 %, time=1.6638s\n",
      "Epoch 7: Loss = 2.045687, accuracy = 30.0000 %, time=1.6404s\n",
      "Epoch 8: Loss = 2.044540, accuracy = 30.0000 %, time=1.7091s\n",
      "Epoch 9: Loss = 2.277424, accuracy = 20.0000 %, time=1.6541s\n",
      "Evaluation on test set: Loss = 2.245724, accuracy = 30.0000 %\n"
     ]
    }
   ],
   "source": [
    "class QCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Hamming weight preserving quantum convolution neural network (k=3)\n",
    "\n",
    "    Tensor dataflow of this network:\n",
    "    input density matrix: (batch,J*I^2,J*I^2)--> conv1: (batch,J*I^2,J*I^2)--> pool1: (batch,J*O^2,J*O^2)\n",
    "    --> conv2: (batch,J*O^2,J*O^2)--> pool2: (batch,J*(O/2)^2,J*(O/2)^2)--> basis_map: (batch,binom(O+J,3),binom(O+J,3))\n",
    "    --> full_dense: (batch,binom(O+J,3),binom(O+J,3)) --> reduce_dim: (batch,binom(5,3)=10,10)\n",
    "    --> reduce_dense: (batch,10,10) --> output measurement: (batch,10)\n",
    "\n",
    "    Then we can use it to calculate the Loss(output, targets)\n",
    "    \"\"\"\n",
    "    def __init__(self, I, O, J, K, k, dense_full_gates, dense_reduce_gates, device):\n",
    "        \"\"\" Args:\n",
    "            - I: dimension of image we use, default I is 28\n",
    "            - O: dimension of image we use after a single pooling\n",
    "            - J: number of convolution channels\n",
    "            - K: size of kernel\n",
    "            - k: preserving subspace parameter, it should be 3\n",
    "            - dense_full_gates: dense gate list, dimension from binom(O+J,3) to binom(5,3)=10\n",
    "            - dense_reduce_gates: reduced dense gate list, dimension from 10 to 10\n",
    "            - device: torch device (cpu, cuda, etc...)\n",
    "        \"\"\"\n",
    "        super(QCNN, self).__init__()\n",
    "        self.conv1 = Conv_RBS_density_I2_3D(I, K, J, device)\n",
    "        self.pool1 = Pooling_3D_density(I, O, J, device)\n",
    "        self.conv2 = Conv_RBS_density_I2_3D(O, K, J, device)\n",
    "        self.pool2 = Pooling_3D_density(O, O // 2, J, device)\n",
    "        self.basis_map = Basis_Change_I_to_HW_density_3D(O // 2, J, k, device)\n",
    "        self.dense_full = Dense_RBS_density_3D(O // 2, J, k, dense_full_gates, device)\n",
    "        self.reduce_dim = Trace_out_dimension(10, device)\n",
    "        self.dense_reduced = Dense_RBS_density_3D(0, 5, k, dense_reduce_gates, device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.conv1(x))  # first convolution and pooling\n",
    "        x = self.pool2(self.conv2(x))  # second convolution and pooling\n",
    "        x = self.basis_map(x)  # basis change from 3D Image to HW=3\n",
    "        x = self.dense_reduced(self.reduce_dim(self.dense_full(x)))  # dense layer\n",
    "        return measurement(x, device)  # measure, only keep the diagonal elements\n",
    "\n",
    "\n",
    "network = QCNN(I, O, J, K, k, dense_full_gates, dense_reduce_gates, device)\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=learning_rate)\n",
    "# Loading data\n",
    "train_loader, test_loader = load.load_MNIST(batch_size=batch_size, shuffle=is_shuffle)\n",
    "reduced_train_loader = load.reduce_MNIST_dataset(train_loader, training_dataset, is_train=True)\n",
    "reduced_test_loader = load.reduce_MNIST_dataset(test_loader, testing_dataset, is_train=False)\n",
    "\n",
    "# training part\n",
    "network_state = train_globally(batch_size, I, J, network, reduced_train_loader, reduced_test_loader, optimizer, criterion, train_epochs, test_interval, stride, device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T09:43:09.095014Z",
     "start_time": "2024-05-27T09:42:51.098954Z"
    }
   },
   "id": "19f7d5e75b1de484"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
