{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Quantum Convolutional Neural Network Example\n",
    "\n",
    "It's a very simple HW3-QCNN, and you can also do further testing by adjusting the hyperparameter, enjoy :)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1: Import packages"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from src.QCNN_layers.Conv_layer import Conv_RBS_density_I2_3D\n",
    "from src.QCNN_layers.Measurement_layer import measurement\n",
    "from src.load_dataset import load_mnist, load_fashion_mnist, load_cifar10\n",
    "from src.QCNN_layers.Pooling_layer import Pooling_3D_density\n",
    "from src.training import train_globally\n",
    "from src.list_gates import slide_circuit, full_connection_circuit, half_connection_circuit, drip_circuit, full_pyramid_circuit\n",
    "from src.QCNN_layers.Dense_layer import Dense_RBS_density_3D, Basis_Change_I_to_HW_density_3D, Trace_out_dimension\n",
    "warnings.simplefilter('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: Define hyperparameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "I = 8  # dimension of image we use. If you use 2 times conv and pool layers, please make it a multiple of 4\n",
    "J = 4  # number of channel for convolution\n",
    "K = 4  # size of kernel in the convolution layer, please make it divisible by O=I/2\n",
    "stride = 1  # the difference in step sizes for different channels\n",
    "batch_size = 10  # batch number\n",
    "kernel_layout = \"pyramid\"  # you can use \"pyramid\" or \"all_connection\"\n",
    "train_dataset_number = 20  # training dataset sample number\n",
    "test_dataset_number = 20  # testing dataset sample number\n",
    "learning_rate = 1e-2 * 0.66  # step size for each learning steps\n",
    "gamma = 0.9  # multiplicative factor of learning rate decay\n",
    "train_epochs = 10  # number of epoch we train\n",
    "test_interval = 10  # when the training epoch reaches an integer multiple of the test_interval, print the testing result\n",
    "output_scale = 30  # Recommended range [10,50]. depends on your other parameters\n",
    "device = torch.device(\"cpu\")  # also torch.device(\"cuda\"), or torch.device(\"mps\") for macbook\n",
    "\n",
    "# Below are the other hyperparameters of this network, usually you don't need to change this\n",
    "O = I // 2  # dimension of image data after one pooling\n",
    "k = 3  # preserving subspace parameter, k=3 for multichannel images, k=2 for single channel images\n",
    "class_set = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]  # filter dataset, 10 labels by default\n",
    "reduced_qubit = 5  # ATTENTION: please let binom(reduced_qubit,k) >= len(class_set)! 5 qubits for 10 labels by default\n",
    "is_shuffle = False  # shuffle for this dataset\n",
    "criterion = torch.nn.CrossEntropyLoss()  # loss function\n",
    "\n",
    "# Here you can modify the dense layer layout, i.e., RBS gate list:\n",
    "# dense_full_gates is for the case qubit=O+J, dense_reduce_gates is for the case qubit=5.\n",
    "# Also, you can check visualization of different gate lists in the file \"src/list_gates.py\"\n",
    "dense_full_gates = drip_circuit(O+J)\n",
    "dense_reduce_gates = full_pyramid_circuit(reduced_qubit)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: Define QCNN structure\n",
    "You can check the code below and match the network layers to this QCNN structure figure"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"../images/QCNN_structure.png\" width=\"1000\">"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class QCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Hamming weight preserving quantum convolution neural network (k=3)\n",
    "\n",
    "    Tensor dataflow of this network:\n",
    "    input density matrix: (batch,J*I^2,J*I^2)--> conv1: (batch,J*I^2,J*I^2)--> pool1: (batch,J*O^2,J*O^2)\n",
    "    --> conv2: (batch,J*O^2,J*O^2)--> pool2: (batch,J*(O/2)^2,J*(O/2)^2)--> basis_map: (batch,binom(O+J,3),binom(O+J,3))\n",
    "    --> full_dense: (batch,binom(O+J,3),binom(O+J,3)) --> reduce_dim: (batch,binom(5,3)=10,10)\n",
    "    --> reduce_dense: (batch,10,10) --> output measurement: (batch,10)\n",
    "\n",
    "    Then we can use it to calculate the Loss(output, targets)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, I, O, J, K, k, kernel_layout, dense_full_gates, dense_reduce_gates, device):\n",
    "        \"\"\" Args:\n",
    "            - I: dimension of image we use, default I is 28\n",
    "            - O: dimension of image we use after a single pooling\n",
    "            - J: number of convolution channels\n",
    "            - K: size of kernel\n",
    "            - k: preserving subspace parameter, it should be 3\n",
    "            - dense_full_gates: dense gate list, dimension from binom(O+J,3) to binom(5,3)=10\n",
    "            - dense_reduce_gates: reduced dense gate list, dimension from 10 to 10\n",
    "            - device: torch device (cpu, cuda, etc...)\n",
    "        \"\"\"\n",
    "        super(QCNN, self).__init__()\n",
    "        self.conv1 = Conv_RBS_density_I2_3D(I, K, J, kernel_layout, device)\n",
    "        self.pool1 = Pooling_3D_density(I, O, J, device)\n",
    "        self.conv2 = Conv_RBS_density_I2_3D(O, K, J, kernel_layout, device)\n",
    "        self.pool2 = Pooling_3D_density(O, O // 2, J, device)\n",
    "        self.basis_map = Basis_Change_I_to_HW_density_3D(O // 2, J, k, device)\n",
    "        self.full_dense = Dense_RBS_density_3D(O // 2, J, k, dense_full_gates, device)\n",
    "        self.reduce_dim = Trace_out_dimension(len(class_set), device)\n",
    "        self.reduced_dense = Dense_RBS_density_3D(0, reduced_qubit, k, dense_reduce_gates, device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.conv1(x))  # first convolution and pooling\n",
    "        x = self.pool2(self.conv2(x))  # second convolution and pooling\n",
    "        x = self.basis_map(x)  # basis change from 3D Image to HW=3\n",
    "        x = self.reduced_dense(self.reduce_dim(self.full_dense(x)))  # dense layer\n",
    "        return measurement(x, device)  # measure, only keep the diagonal elements"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 4: Training this network\n",
    "Because our structure is very simple but the task is difficult (10 labels classification), the results usually aren't ideal. However, you can see the optimization process and then try larger structures.\n",
    "E.g. you can increase the value of I (image size), J (number of channel), train_dataset_number, etc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Start training! Number of network total parameters: 68\n",
      "Evaluation on test set: Loss = 5.028995, accuracy = 5.0000 %\n",
      "Epoch 0: Loss = 4.327963, accuracy = 10.0000 %, time=1.2963s\n",
      "Epoch 1: Loss = 2.631864, accuracy = 10.0000 %, time=1.2935s\n",
      "Epoch 2: Loss = 2.535542, accuracy = 10.0000 %, time=1.2564s\n",
      "Epoch 3: Loss = 2.551582, accuracy = 15.0000 %, time=1.2709s\n",
      "Epoch 4: Loss = 2.542899, accuracy = 15.0000 %, time=1.2609s\n",
      "Epoch 5: Loss = 2.537460, accuracy = 10.0000 %, time=1.2774s\n",
      "Epoch 6: Loss = 2.494689, accuracy = 5.0000 %, time=1.3660s\n",
      "Epoch 7: Loss = 2.473959, accuracy = 10.0000 %, time=1.4198s\n",
      "Epoch 8: Loss = 2.450714, accuracy = 15.0000 %, time=1.3247s\n",
      "Epoch 9: Loss = 2.438900, accuracy = 15.0000 %, time=1.3141s\n",
      "Evaluation on test set: Loss = 2.598509, accuracy = 5.0000 %\n"
     ]
    }
   ],
   "source": [
    "network = QCNN(I, O, J, K, k, kernel_layout, dense_full_gates, dense_reduce_gates, device)\n",
    "# network.load_state_dict(torch.load(\"QCNN_modelState\")) # you can load the network parameter file, otherwise it will be initialized randomly\n",
    "\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=learning_rate)\n",
    "scheduler = ExponentialLR(optimizer, gamma=gamma) # learning rate decay\n",
    "\n",
    "# Loading dataset, you can choose the dataset you want to use: MNIST/FashionMNIST/CIFAR-10\n",
    "print(\"Loading dataset...\")\n",
    "train_dataloader, test_dataloader = load_mnist(class_set, train_dataset_number, test_dataset_number, batch_size)\n",
    "# train_dataloader, test_dataloader = load_cifar10(class_set, train_dataset_number, test_dataset_number, batch_size)\n",
    "# train_dataloader, test_dataloader = load_fashion_mnist(class_set, train_dataset_number, test_dataset_number, batch_size)\n",
    "\n",
    "# Starting training\n",
    "network_state, training_loss_list, training_accuracy_list, testing_loss_list, testing_accuracy_list = train_globally(batch_size, I, J, network, train_dataloader, test_dataloader, optimizer, scheduler, criterion, output_scale,train_epochs, test_interval, stride, device)\n",
    "\n",
    "# Saving network parameters\n",
    "torch.save(network_state, \"Model_states/QCNN_3DmodelState\")\n",
    "result_data = {'train_accuracy': training_accuracy_list,'train_loss': training_loss_list,'test_accuracy': testing_accuracy_list,'test_loss': testing_loss_list,}\n",
    "file_path = 'Model_states/plot_data_3D.npy'\n",
    "np.save(file_path, result_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}