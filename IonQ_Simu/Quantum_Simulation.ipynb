{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<style>\n",
    "u { color: red; }\n",
    ".red { color: white }\n",
    "</style>\n",
    "# <u><span class='red'><br>Subspace Preserving Deep Learning: IonQ Implementation</span></u>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook, we present our codes to simulate the behavior of Hamming Weight (HW) preserving quantum circuits made of RBS, and CNOTs gates. The simulation are done using python numpy and pytorch library, in a specific subspace by the HW $k$ or a specific encoding which allows one to have better perfomances that using simulation in a IDE that simulate the entire Hilbert space.\n",
    "\n",
    "We propose to use the encoding algorithm from [arXiv:2309.15547](https://arxiv.org/pdf/2309.15547) to minimize the depth of the quantum circuit. We then perform binary classification using the QCNN for $8 \\times 8$ images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import here some useful libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.abspath('')))\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from scipy.special import binom\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load function from our simulation python files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IonQ_Simu.toolbox import *\n",
    "from IonQ_Simu.Encoding_Algorithms import RBS_tensor_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>Tensor Encoding<mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of the RBS based quantum data loader:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define the Quantum Data Loader using our encoding algorithms based on a study of the Quantum Fisher Information Matrix (QFIM). We consider the full connectivity of the IonQ device.\n",
    "\n",
    "We ask our Algorithm to derive a quantum data loader using $n=16$ qubits with a corresponding HW $k=2$. The connectivity is define as a list of edges called __ListEdges__. Our Encoding algorithm outputs a list of RBS gates. A RBS gate applied between the qubit $i$ and the qubit $j$ is represented as a tuple $(i,j)$.   \n",
    "\n",
    "Considering tensor encoding, we want to encode images of dimension $I \\times I$ with $I=8$. The input are matrices $x \\in \\mathbb{R}^{I \\times I}$. We then need $I^2 - 1$ degrees of freedom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 723.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum Data Loader successfully designed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Quantum circuit definition:\n",
    "I = 3\n",
    "# Connectivity Graph\n",
    "Qubits = [Vertex(\"q{}\".format(i), i) for i in range(2*I)]\n",
    "ListEdges = [Edge(Qubits[i],Qubits[j]) for i in range(2*I) for j in range(i+1,2*I)]\n",
    "Graph_Connectivity = Network(Qubits, ListEdges)\n",
    "\n",
    "# We apply our encoding algorithm RBS_subspace_encoding_1_heuristic\n",
    "QDL = RBS_tensor_encoding(I, Graph_Connectivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aadb8c",
   "metadata": {},
   "source": [
    "### Fashion MNIST dataset\n",
    "\n",
    "We import the Fashion MNIST dataset. We preprocess it to have $I \\times I$ images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60ce413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from IonQ_Simu.dataset import load_image_states_fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a02c88ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training images and labels:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 2253.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading testing images and labels:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 2560.53it/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\")\n",
    "\n",
    "# Data loading parameters:\n",
    "class_set = [0,1] # We only consider the classes 0 and 1 (binary classification)\n",
    "train_dataset_number, test_dataset_number = int(1e3), int(1e3)\n",
    "\n",
    "train_init_states, test_init_states, train_labels, test_labels = load_image_states_fashion_mnist(I, class_set, train_dataset_number, test_dataset_number, device)\n",
    "\n",
    "# Save the initial states and labels\n",
    "torch.save(train_init_states, 'train_init_states.pt')\n",
    "torch.save(test_init_states, 'test_init_states.pt')\n",
    "torch.save(train_labels, 'train_labels.pt')\n",
    "torch.save(test_labels, 'test_labels.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d5477fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IonQ_Simu.toolbox import RBS_generalized, map_RBS\n",
    "from src.toolbox import map_RBS_Image_HW2, dictionary_RBS_I2_2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeccddb",
   "metadata": {},
   "source": [
    "### Training the data loader:\n",
    "\n",
    "We simulate our data loader using our torch modules for subspace preserving simulation. We train our data loader for each initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3079931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.RBS_Circuit import RBS_VQC_state_vector\n",
    "from IonQ_Simu.Encoding_Algorithms import global_training_quantum_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "608bf165",
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoding_Load = False\n",
    "Data_Loading = RBS_VQC_state_vector(2*I, 2, QDL, device)\n",
    "if Encoding_Load:\n",
    "    train_encoded_parameters, test_encoded_parameters = global_training_quantum_data_loader(Data_Loading, train_init_states, test_init_states, device)\n",
    "    torch.save(train_encoded_parameters, 'train_encoded_parameters.pt')\n",
    "    torch.save(test_encoded_parameters, 'test_encoded_parameters.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8066dee8",
   "metadata": {},
   "source": [
    "We can test the quality of the data loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23f616ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1699, device='mps:0', grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Initial state (corresponding to initial bit flips):\n",
    "initial_state = torch.zeros(int(binom(2*I,2)), device=device)\n",
    "initial_state[0] = 1\n",
    "\n",
    "# Change of basis:\n",
    "I = int(np.sqrt(train_init_states.shape[1]))\n",
    "dict_I2, map_RBS_HW2 = dictionary_RBS_I2_2D(I), map_RBS(2*I,2)\n",
    "\n",
    "sample = torch.from_numpy(map_RBS_Image_HW2(I, dict_I2, map_RBS_HW2, test_init_states[-1])).type(torch.float32).to(device)\n",
    "print(torch.nn.MSELoss()(Data_Loading(initial_state), sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0170e1ad",
   "metadata": {},
   "source": [
    "## <mark>Quantum Convolutional Neural Network architecture<mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b47cb4",
   "metadata": {},
   "source": [
    "### Defining the architecture and training it\n",
    "\n",
    "In this Section, we define the architecture and we train it. First, let us load some useful python libraries and define the hyperparameters of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3058f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.list_gates import drip_circuit, full_pyramid_circuit\n",
    "from src.load_dataset import load_fashion_mnist\n",
    "from src.training import train_globally_2D\n",
    "from IonQ_Simu.QCNN_2D import QCNN\n",
    "\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ef0768a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below are the hyperparameters of this network, you can change them to test\n",
    "I = 3  # dimension of image we use. If you use 2 times conv and pool layers, please make it a multiple of 4\n",
    "O = I // 2  # dimension after pooling, usually you don't need to change this\n",
    "K = 2  # size of kernel in the convolution layer, please make it divisible by O=I/2\n",
    "batch_size = 10  # batch number\n",
    "reduced_qubit = 3 # ATTENTION: let binom(reduced_qubit,k) >= len(class_set)!\n",
    "is_shuffle = False  # shuffle for this dataset\n",
    "learning_rate = 1e-1  # step size for each learning steps\n",
    "train_epochs = 10  # number of epoch we train\n",
    "test_interval = 1  # when the training epoch reaches an integer multiple of the test_interval, print the testing result\n",
    "criterion = torch.nn.CrossEntropyLoss()  # loss function\n",
    "device = torch.device(\"mps\")  # also torch.device(\"cpu\"), or torch.device(\"cuda\") for gpus\n",
    "output_scale = 10\n",
    "\n",
    "# Dense part:\n",
    "dense_full_gates = drip_circuit(I)\n",
    "dense_reduce_gates = full_pyramid_circuit(reduced_qubit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d501c4",
   "metadata": {},
   "source": [
    "We use our pytorch modules to simulate a Quantum Convolutional Neural Network architecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc352a89",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "network = QCNN(I, O, dense_full_gates, dense_reduce_gates, reduced_qubit, device)\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=learning_rate)\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "# Loading data\n",
    "train_dataloader, test_dataloader = load_fashion_mnist(class_set, train_dataset_number, test_dataset_number, batch_size)\n",
    "# train_dataloader, test_dataloader = load_mnist(class_set, train_dataset_number, test_dataset_number, batch_size)\n",
    "\n",
    "# training part\n",
    "network_state = train_globally_2D(batch_size, I, network, train_dataloader, test_dataloader, optimizer, scheduler, criterion, output_scale, train_epochs, test_interval, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20be55d6",
   "metadata": {},
   "source": [
    "## <mark>PennyLane Simulation<mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f1096c",
   "metadata": {},
   "source": [
    "In this Section, we define the PennyLane simulations of our quantum encoding and machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2834d9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "\n",
    "from Verification_correction.PennyLane_toolbox import RBS, Conv_RBS_2D, Pool_2D, dense_RBS\n",
    "from src.toolbox import QCNN_RBS_based_VQC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad8d362",
   "metadata": {},
   "source": [
    "We define the global circuit (encoding + qcnn) using the pennylane library. The circuit should be the same as described in the previous sections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f63141",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=2*I)\n",
    "\n",
    "def Global_QCNN_Circuit(I, K, angles_QDL, angles_conv, angles_dense):\n",
    "    # Initial state preparation\n",
    "    qml.PauliX(wires=0)\n",
    "    qml.PauliX(wires=1)\n",
    "    # Quantum data loader\n",
    "    for i,(a,b) in enumerate(QDL):\n",
    "        RBS(a, b, angles_QDL[i])\n",
    "    # Convolutional layer\n",
    "    Conv_RBS_2D(angles_conv, I, K) \n",
    "    # Pooling layer\n",
    "    Pool_2D([i for i in range(2*I)])\n",
    "    # Dense layer\n",
    "    for index,(i,j) in enumerate(dense_full_gates):\n",
    "        RBS(i*2 +1, j*2 +1, angles_dense[index])\n",
    "    for index, (i,j) in enumerate(dense_reduce_gates):\n",
    "        RBS(i*2 +1, j*2 +1, angles_dense[len(dense_full_gates)+index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
