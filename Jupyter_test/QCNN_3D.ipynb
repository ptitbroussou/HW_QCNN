{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-24T13:52:44.053653Z",
     "start_time": "2024-05-24T13:52:44.042461Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/11/3v4yjwwj59gc60lpr8h0kh780000gn/T/ipykernel_26334/477154950.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msys\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0msys\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdirname\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdirname\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mabspath\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m__file__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mwarnings\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "from Conv_Layer import Conv_RBS_density_I2_3D\n",
    "import torch\n",
    "import time\n",
    "from Measurement import map_HW_to_measure\n",
    "from Pooling import Pooling_3D_density\n",
    "import torch.nn as nn  # the neural network library of pytorch\n",
    "import load_dataset as load  # module with function to load MNIST\n",
    "from training import test_net, train_net, train_net_stride, test_net_stride\n",
    "from Dense import Dense_RBS_density_3D, Basis_Change_I_to_HW_density_3D, Trace_out_dimension\n",
    "from List_gates import butterfly_bi_gates, butterfly_gates, X_gates, full_pyramid_gates, get_reduced_layers_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class QCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Pyramid Quantum convolution neural network by using Jonas's method to predict labels.\n",
    "    \"\"\"\n",
    "    def __init__(self, I, O, J, K, k, device):\n",
    "        \"\"\" Args:\n",
    "            - I: dimension of image we use, default I is 28\n",
    "            - O: dimension of image we use after a single pooling\n",
    "            - J: number of convolution channels\n",
    "            - K: size of kernel\n",
    "            - k: preserving subspace parameter, it should be 3\n",
    "            - device: torch device (cpu, cuda, etc...)\n",
    "        \"\"\"\n",
    "        super(QCNN, self).__init__()\n",
    "\n",
    "        #  Arrangement of rectangular pyramid dense gates\n",
    "        list_gates_full_pyramid = get_reduced_layers_structure((O//1) + (J//1), 5)\n",
    "        # Here we only keep the last 5 qubits, because 5 qubits represents 10 dimension with k=3, 10 dimension corresponds to 10 labels\n",
    "        # Arrangement of pyramid dense gates with only 5 qubits\n",
    "        list_gates_reduced_pyramid = full_pyramid_gates(5)\n",
    "        list_gates_full = [(i, j) for i in range((O//1)+(J//1)) for j in range((O//1)+(J//1)) if i != j]\n",
    "        list_gates_full_reverse = [(i, j) for i in range((O//1)+(J//1)) for j in range((O//1)+(J//1)) if i != j]\n",
    "        list_gates_reduced = [(i, j) for i in range(5) for j in range(5) if i != j]\n",
    "        list_gates_reduced_reverse = [(j, i) for i in range(5) for j in range(5) if i != j]\n",
    "        list_gates_full_plane = [(i, i+1) for i in range((O//1) + (J//1)-1)]\n",
    "\n",
    "        # 3 conv QCNN layers\n",
    "        self.conv1 = Conv_RBS_density_I2_3D(I,K,J,device)\n",
    "        self.pool1 = Pooling_3D_density(I, O, J, device)\n",
    "        self.conv2 = Conv_RBS_density_I2_3D(O,K,J//1,device)\n",
    "        self.pool2 = Pooling_3D_density(O, O//2, J//1, device)\n",
    "        self.basis_map = Basis_Change_I_to_HW_density_3D(O//2, J//1, k, device)\n",
    "        self.dense_full1 = Dense_RBS_density_3D(O//2, J//1, k, list_gates_full, device)\n",
    "        self.dense_full2 = Dense_RBS_density_3D(O//2, J//1, k, butterfly_bi_gates(O//2+J), device)\n",
    "        self.dense_full3 = Dense_RBS_density_3D(O//2, J//1, k, list_gates_full_reverse, device)\n",
    "        self.dense_full4 = Dense_RBS_density_3D(O//2, J//1, k, butterfly_gates(O//2+J), device)\n",
    "        self.dense_full5 = Dense_RBS_density_3D(O//2, J//1, k, list_gates_full, device)\n",
    "        self.dense_full6 = Dense_RBS_density_3D(O//2, J//1, k, X_gates(O//2+J), device)\n",
    "        self.dense_full7 = Dense_RBS_density_3D(O//2, J//1, k, list_gates_full_reverse, device)\n",
    "        self.dense_full8 = Dense_RBS_density_3D(O//2, J//1, k, list_gates_full_plane, device)\n",
    "        self.reduce_dim = Trace_out_dimension(10, device)\n",
    "        self.dense_reduced1 = Dense_RBS_density_3D(0, 5, k, list_gates_reduced, device)\n",
    "        self.dense_reduced2 = Dense_RBS_density_3D(0, 5, k, butterfly_gates(5), device)\n",
    "        self.dense_reduced3 = Dense_RBS_density_3D(0, 5, k, list_gates_reduced_reverse, device)\n",
    "        self.dense_reduced4 = Dense_RBS_density_3D(0, 5, k, X_gates(5), device)\n",
    "        self.dense_reduced5 = Dense_RBS_density_3D(0, 5, k, list_gates_reduced, device)\n",
    "        self.dense_reduced6 = Dense_RBS_density_3D(0, 5, k, list_gates_reduced_reverse, device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        # c3 = self.conv3(p2)\n",
    "        # p3 = self.pool3(c3)\n",
    "        x = self.basis_map(x)\n",
    "        x = self.dense_full7(self.dense_full7(self.dense_full6(self.dense_full5(self.dense_full4(self.dense_full3(self.dense_full2(self.dense_full1(x))))))))\n",
    "        # x = self.dense_full8(self.dense_full7((self.dense_full5(self.dense_full3(self.dense_full1(x))))))\n",
    "        x = self.reduce_dim(x)\n",
    "        x = self.dense_reduced6(self.dense_reduced5(self.dense_reduced4(self.dense_reduced3(self.dense_reduced2(self.dense_reduced1(x))))))\n",
    "        # d= (self.dense_reduced3(self.dense_reduced1(to)))\n",
    "        x = map_HW_to_measure(x, device) # only keep the diagonal elements\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T13:49:12.437561Z",
     "start_time": "2024-05-24T13:49:12.434764Z"
    }
   },
   "id": "5e6b9a96bbdabe28"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "##################### Meta-parameters begin #######################\n",
    "I = 16  # dimension of image we use\n",
    "O = I // 2  # dimension after pooling\n",
    "J = 2  # number of channel\n",
    "k = 3 # preserving subspace parameter\n",
    "K = 2  # size of kernel\n",
    "batch_size = 10  # batch number\n",
    "scala_train = 6000  # multiple that we reduce train dataset\n",
    "scala_test = 1000 # multiple that we reduce test dataset\n",
    "learning_rate = 2e-3\n",
    "device = torch.device(\"mps\") # if you are testing in your PC, you can use torch.device(\"cpu\")\n",
    "##################### Meta-parameters end #######################\n",
    "\n",
    "# Loading data\n",
    "train_loader, test_loader = load.load_MNIST(batch_size=batch_size)\n",
    "reduced_loader = load.reduce_MNIST_dataset(train_loader, scala_train)\n",
    "reduced_test_loader = load.reduce_MNIST_dataset(test_loader, scala_test)\n",
    "\n",
    "conv_network = QCNN(I, O, J, K, k, device)\n",
    "optimizer = torch.optim.Adam(conv_network.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T13:49:29.136650Z",
     "start_time": "2024-05-24T13:49:26.404052Z"
    }
   },
   "id": "e0b62033b34e5d2c"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 2.427300, accuracy = 0.0000 %, time=6.3236s\n",
      "Evaluation on test set: Loss = 2.361782, accuracy = 0.0000 %\n",
      "Epoch 1: Loss = 2.366457, accuracy = 0.0000 %, time=5.7026s\n",
      "Evaluation on test set: Loss = 2.324281, accuracy = 0.0000 %\n"
     ]
    }
   ],
   "source": [
    "# training part\n",
    "loss_list = []\n",
    "accuracy_list = []\n",
    "for epoch in range(2):\n",
    "    start = time.time()\n",
    "    train_loss, train_accuracy = train_net_stride(batch_size, I, J, k, conv_network, train_loader, criterion, optimizer, device)\n",
    "    loss_list.append(train_loss)\n",
    "    accuracy_list.append(train_accuracy * 100)\n",
    "    end = time.time()\n",
    "    print(f'Epoch {epoch}: Loss = {train_loss:.6f}, accuracy = {train_accuracy * 100:.4f} %, time={(end-start):.4f}s')\n",
    "    if ((epoch % 5 == 0)):\n",
    "        # if ((epoch % 5 == 0) and (epoch != 0)):\n",
    "        test_loss, test_accuracy = test_net_stride(batch_size, I, J, k, conv_network, reduced_test_loader, criterion, device)\n",
    "        print(f'Evaluation on test set: Loss = {test_loss:.6f}, accuracy = {test_accuracy * 100:.4f} %')\n",
    "\n",
    "# testing part\n",
    "test_loss, test_accuracy = test_net_stride(batch_size, I, J, k, conv_network, reduced_test_loader, criterion, device)\n",
    "print(f'Evaluation on test set: Loss = {test_loss:.6f}, accuracy = {test_accuracy * 100:.4f} %')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T13:49:46.121824Z",
     "start_time": "2024-05-24T13:49:29.826504Z"
    }
   },
   "id": "af687d35b9095bca"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 691\n"
     ]
    }
   ],
   "source": [
    "I = 16 # dimension of image we use\n",
    "O = I//2 # dimension after pooling\n",
    "J = 4 # number of channel\n",
    "k = 3\n",
    "K = 2 # size of kernel\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "conv_network = QCNN(I, O, J, K, k, device)\n",
    "total_params = sum(p.numel() for p in conv_network.parameters())\n",
    "print(f\"Number of parameters: {total_params}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T13:50:19.467939Z",
     "start_time": "2024-05-24T13:50:13.431595Z"
    }
   },
   "id": "c8d3e3b8da1527b2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(conv_network.state_dict(), \"model\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aeaf177166a43c27"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
